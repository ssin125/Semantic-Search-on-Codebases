{"cells":[{"cell_type":"markdown","metadata":{"id":"J9PdcaX8den4"},"source":["# Semantic Code Search using Transformers - Part I \n","by:\n","### Maj Ashish Ahluwalia (21111073) ashisha21@iitk.ac.in\n","### Binay Kumar Suna (21111021) binayas21@iitk.ac.in\n","### Chabil Kansal (21111022) chabilk21@iitk.ac.in\n","### Shubham Sinha (21111409) shubhams21@iitk.ac.in\n"]},{"cell_type":"code","source":["# Mount your drive which contains the CS657 IR PROJECT folder containing the data (\"python folder\")\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"itdpyebrdomu","executionInfo":{"status":"ok","timestamp":1650976793461,"user_tz":-330,"elapsed":3322,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"52a8123d-d9ce-434b-d681-bf97ae82eaf5"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install astor"],"metadata":{"id":"5pbO54UdEb9j"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":60,"metadata":{"id":"nzzkVC8vden8","executionInfo":{"status":"ok","timestamp":1650976793462,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["#importing libraries\n","\n","import ast\n","import sqlite3\n","\n","import glob\n","import re\n","import numpy as np\n","from pathlib import Path\n","import os\n","import json\n","\n","\n","import astor\n","import pandas as pd\n","from nltk.tokenize import RegexpTokenizer\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LEYeo7VOdeoA","executionInfo":{"status":"ok","timestamp":1650976793462,"user_tz":-330,"elapsed":5,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"f9ca80d4-6872-4fec-89af-1a1e193288ef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['python_train_0.jsonl',\n"," 'python_train_1.jsonl',\n"," 'python_train_2.jsonl',\n"," 'python_train_3.jsonl',\n"," 'python_train_4.jsonl',\n"," 'python_train_5.jsonl',\n"," 'python_train_6.jsonl',\n"," 'python_train_7.jsonl',\n"," 'python_train_8.jsonl',\n"," 'python_train_9.jsonl',\n"," 'python_train_10.jsonl',\n"," 'python_train_11.jsonl',\n"," 'python_train_12.jsonl',\n"," 'python_train_13.jsonl',\n"," 'python_valid_0.jsonl',\n"," 'python_test_0.jsonl']"]},"metadata":{},"execution_count":64}],"source":["data_list = os.listdir(\"drive/MyDrive/CS657 IR PROJECT/python/jsonl/complete/\")\n","# data_list\n","df = pd.DataFrame(columns=['nwo','path','function_name','original_function','function_tokens','docstring_tokens','url'])\n","# df\n","data_list"]},{"cell_type":"code","execution_count":65,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"u3voW-ChdeoA","executionInfo":{"status":"ok","timestamp":1650976810548,"user_tz":-330,"elapsed":17089,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"812a0250-32af-4762-8afd-b89ebaef0413"},"outputs":[{"output_type":"stream","name":"stdout","text":["python_train_0.jsonl\n","30000\n","python_train_1.jsonl\n","30000\n","python_train_2.jsonl\n","30000\n","python_train_3.jsonl\n","30000\n","python_train_4.jsonl\n","30000\n","python_train_5.jsonl\n","30000\n","python_train_6.jsonl\n","30000\n","Out\n"]},{"output_type":"execute_result","data":{"text/plain":["                            nwo                              path  \\\n","0       face_recognition_knn.py  examples/face_recognition_knn.py   \n","1       face_recognition_knn.py  examples/face_recognition_knn.py   \n","2       face_recognition_knn.py  examples/face_recognition_knn.py   \n","3                        api.py           face_recognition/api.py   \n","4                        api.py           face_recognition/api.py   \n","...                         ...                               ...   \n","209995                 folia.py           pynlpl/formats/folia.py   \n","209996                 folia.py           pynlpl/formats/folia.py   \n","209997                 folia.py           pynlpl/formats/folia.py   \n","209998                 folia.py           pynlpl/formats/folia.py   \n","209999                 folia.py           pynlpl/formats/folia.py   \n","\n","                          function_name  \\\n","0                                 train   \n","1                               predict   \n","2       show_prediction_labels_on_image   \n","3                          _rect_to_css   \n","4                   _trim_css_to_bounds   \n","...                                 ...   \n","209995   AbstractElement.speech_speaker   \n","209996             AbstractElement.phon   \n","209997             AbstractElement.feat   \n","209998             AbstractElement.copy   \n","209999     AbstractElement.copychildren   \n","\n","                                                  content  \\\n","0       def train(train_dir, model_save_path=None, n_n...   \n","1       def predict(X_img_path, knn_clf=None, model_pa...   \n","2       def show_prediction_labels_on_image(img_path, ...   \n","3       def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n","4       def _trim_css_to_bounds(css, image_shape):\\n  ...   \n","...                                                   ...   \n","209995  def speech_speaker(self):\\n        \"\"\"Retrieve...   \n","209996  def phon(self, cls='current', previousdelimite...   \n","209997  def feat(self,subset):\\n        \"\"\"Obtain the ...   \n","209998  def copy(self, newdoc=None, idsuffix=\"\"):\\n   ...   \n","209999  def copychildren(self, newdoc=None, idsuffix=\"...   \n","\n","                                         docstring_tokens  \\\n","0       Trains a k - nearest neighbors classifier for ...   \n","1       Recognizes faces in given image using a traine...   \n","2           Shows the face recognition results visually .   \n","3       Convert a dlib rect object to a plain tuple in...   \n","4       Make sure a tuple in ( top right bottom left )...   \n","...                                                   ...   \n","209995  Retrieves the speaker of the audio or video fi...   \n","209996  Get the phonetic representation associated wit...   \n","209997  Obtain the feature class value of the specific...   \n","209998  Make a deep copy of this element and all its c...   \n","209999  Generator creating a deep copy of the children...   \n","\n","                                                      url  \n","0       https://github.com/ageitgey/face_recognition/b...  \n","1       https://github.com/ageitgey/face_recognition/b...  \n","2       https://github.com/ageitgey/face_recognition/b...  \n","3       https://github.com/ageitgey/face_recognition/b...  \n","4       https://github.com/ageitgey/face_recognition/b...  \n","...                                                   ...  \n","209995  https://github.com/proycon/pynlpl/blob/7707f69...  \n","209996  https://github.com/proycon/pynlpl/blob/7707f69...  \n","209997  https://github.com/proycon/pynlpl/blob/7707f69...  \n","209998  https://github.com/proycon/pynlpl/blob/7707f69...  \n","209999  https://github.com/proycon/pynlpl/blob/7707f69...  \n","\n","[210000 rows x 6 columns]"],"text/html":["\n","  <div id=\"df-2012cd4b-d941-4c5f-94da-f9c9fd864a17\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nwo</th>\n","      <th>path</th>\n","      <th>function_name</th>\n","      <th>content</th>\n","      <th>docstring_tokens</th>\n","      <th>url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>train</td>\n","      <td>def train(train_dir, model_save_path=None, n_n...</td>\n","      <td>Trains a k - nearest neighbors classifier for ...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>predict</td>\n","      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n","      <td>Recognizes faces in given image using a traine...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>show_prediction_labels_on_image</td>\n","      <td>def show_prediction_labels_on_image(img_path, ...</td>\n","      <td>Shows the face recognition results visually .</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_rect_to_css</td>\n","      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n","      <td>Convert a dlib rect object to a plain tuple in...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_trim_css_to_bounds</td>\n","      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n","      <td>Make sure a tuple in ( top right bottom left )...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>209995</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.speech_speaker</td>\n","      <td>def speech_speaker(self):\\n        \"\"\"Retrieve...</td>\n","      <td>Retrieves the speaker of the audio or video fi...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","    </tr>\n","    <tr>\n","      <th>209996</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.phon</td>\n","      <td>def phon(self, cls='current', previousdelimite...</td>\n","      <td>Get the phonetic representation associated wit...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","    </tr>\n","    <tr>\n","      <th>209997</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.feat</td>\n","      <td>def feat(self,subset):\\n        \"\"\"Obtain the ...</td>\n","      <td>Obtain the feature class value of the specific...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","    </tr>\n","    <tr>\n","      <th>209998</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.copy</td>\n","      <td>def copy(self, newdoc=None, idsuffix=\"\"):\\n   ...</td>\n","      <td>Make a deep copy of this element and all its c...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","    </tr>\n","    <tr>\n","      <th>209999</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.copychildren</td>\n","      <td>def copychildren(self, newdoc=None, idsuffix=\"...</td>\n","      <td>Generator creating a deep copy of the children...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>210000 rows × 6 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2012cd4b-d941-4c5f-94da-f9c9fd864a17')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2012cd4b-d941-4c5f-94da-f9c9fd864a17 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2012cd4b-d941-4c5f-94da-f9c9fd864a17');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":65}],"source":["list_of_dict = []\n","d = {}\n","for file in data_list[:7]:\n","    with open('drive/MyDrive/CS657 IR PROJECT/python/jsonl/complete/' + file, 'r') as json_file:\n","        json_list = list(json_file)\n","    for json_str in json_list:\n","        result = json.loads(json_str)\n","        list_of_dict.append(result)\n","    print(file)\n","    print(len(json_list))\n","i = 0\n","print(\"Out\")\n","for entry in list_of_dict:\n","    d[i] = {'nwo':str(entry['path']).split('/')[-1],\n","                  'path':entry['path'],\n","                  'function_name':entry['func_name'],\n","                  'content':entry['code'],\n","                  'docstring_tokens':' '.join(entry['docstring_tokens']),\n","                  'url':entry['url']}\n","    i = i + 1\n","\n","df = pd.DataFrame.from_dict(d,\"index\")\n","df"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"hbmXZo9YdeoC","executionInfo":{"status":"ok","timestamp":1650976810550,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["def tokenize_docstring(text):\n","    \"\"\"Gets filetered docstring tokens which help describe the function\"\"\"\n","    \n","    # Remove decorators and other parameter signatures in the docstring\n","    before_keyword, keyword, after_keyword = text.partition(':')\n","    before_keyword, keyword, after_keyword = before_keyword.partition('@param')\n","    before_keyword, keyword, after_keyword = before_keyword.partition('param')\n","    before_keyword, keyword, after_keyword = before_keyword.partition('@brief')\n","    \n","    if(after_keyword):    \n","        words = RegexpTokenizer(r'[a-zA-Z0-9]+').tokenize(after_keyword)\n","    else:\n","        before_keyword, keyword, after_keyword = before_keyword.partition('@')\n","        words = RegexpTokenizer(r'[a-zA-Z0-9]+').tokenize(before_keyword)\n","        \n","    # Convert all docstrings to lowercase\n","    new_words= [word.lower() for word in words if word.isalnum()]\n","    \n","    return new_words\n","\n","\n","def tokenize_code(text):\n","    \"\"\"Gets filetered fucntion tokens\"\"\"\n","    \n","    # Remove decorators and function signatures till the def token\n","    keyword = 'def '\n","    before_keyword, keyword, after_keyword = text.partition(keyword)\n","    words = RegexpTokenizer(r'[a-zA-Z0-9]+').tokenize(after_keyword)\n","    \n","    # Convert function tokens to lowercase and remove single alphabet variables\n","    new_words= [word.lower() for word in words if (word.isalpha() and len(word)>1) or (word.isnumeric())]\n","    return new_words\n","\n","\n","def get_function_docstring_pairs(blob):\n","    \"Extracts (function/method, docstring) pairs from a given code blob.\"\n","    \n","    pairs = []\n","    try:\n","        module = ast.parse(blob) # Converts the python code into an abstract syntx tree\n","        classes = [node for node in module.body if isinstance(node, ast.ClassDef)] # Retrieves classes from source code\n","        functions = [node for node in module.body if isinstance(node, ast.FunctionDef)] # Retrieves functions from the source code\n","        for _class in classes:\n","            functions.extend([node for node in _class.body if isinstance(node, ast.FunctionDef)]) # Retrieves functions from the classes extracted\n","\n","        for f in functions:\n","            source = astor.to_source(f) # Convert the functions extracted into ast format so as to remove comments\n","            docstring = ast.get_docstring(f) if ast.get_docstring(f) else '' # Get docstring from fucntion definition if present\n","            function = source.replace(ast.get_docstring(f, clean=False), '') if docstring else source # function definition without any comments\n","            \n","            # Extracts function name, line number of the function in the source code, original function, function tokens and docstring tokens \n","            pairs.append((f.name,         \n","                          f.lineno,\n","                          source,\n","                          ' '.join(tokenize_code(function)),\n","                          ' '.join(tokenize_docstring(docstring.split('\\n\\n')[0]))\n","                         ))\n","    except (AssertionError, MemoryError, SyntaxError, UnicodeEncodeError):\n","        pass\n","    return pairs\n","\n","\n","def get_function_docstring_pairs_list(blob_list):\n","    \"\"\"apply the function `get_function_docstring_pairs` on a list of blobs\"\"\"\n","    return [get_function_docstring_pairs(b) for b in blob_list]"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"C5jwTT7wdeoD","executionInfo":{"status":"ok","timestamp":1650976810550,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["x = df.content.tolist()"]},{"cell_type":"code","execution_count":71,"metadata":{"scrolled":true,"id":"F7dkH8TtdeoD","executionInfo":{"status":"ok","timestamp":1650976992747,"user_tz":-330,"elapsed":181568,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["func_doc = get_function_docstring_pairs_list(df.content.tolist())"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZbW2ZLsCdeoD","executionInfo":{"status":"ok","timestamp":1650976992750,"user_tz":-330,"elapsed":18,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"fd928492-7a32-409d-e94b-a602a79930fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["210000"]},"metadata":{},"execution_count":72}],"source":["len(func_doc) "]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"ncV6XSyhdeoD","executionInfo":{"status":"ok","timestamp":1650976992751,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"860dbd4a-5c61-4b93-8285-6a710218b8b9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                       nwo                              path  \\\n","0  face_recognition_knn.py  examples/face_recognition_knn.py   \n","1  face_recognition_knn.py  examples/face_recognition_knn.py   \n","2  face_recognition_knn.py  examples/face_recognition_knn.py   \n","3                   api.py           face_recognition/api.py   \n","4                   api.py           face_recognition/api.py   \n","\n","                     function_name  \\\n","0                            train   \n","1                          predict   \n","2  show_prediction_labels_on_image   \n","3                     _rect_to_css   \n","4              _trim_css_to_bounds   \n","\n","                                             content  \\\n","0  def train(train_dir, model_save_path=None, n_n...   \n","1  def predict(X_img_path, knn_clf=None, model_pa...   \n","2  def show_prediction_labels_on_image(img_path, ...   \n","3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n","4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n","\n","                                    docstring_tokens  \\\n","0  Trains a k - nearest neighbors classifier for ...   \n","1  Recognizes faces in given image using a traine...   \n","2      Shows the face recognition results visually .   \n","3  Convert a dlib rect object to a plain tuple in...   \n","4  Make sure a tuple in ( top right bottom left )...   \n","\n","                                                 url  \\\n","0  https://github.com/ageitgey/face_recognition/b...   \n","1  https://github.com/ageitgey/face_recognition/b...   \n","2  https://github.com/ageitgey/face_recognition/b...   \n","3  https://github.com/ageitgey/face_recognition/b...   \n","4  https://github.com/ageitgey/face_recognition/b...   \n","\n","                                               pairs  \n","0  [(train, 1, def train(train_dir, model_save_pa...  \n","1  [(predict, 1, def predict(X_img_path, knn_clf=...  \n","2  [(show_prediction_labels_on_image, 1, def show...  \n","3  [(_rect_to_css, 1, def _rect_to_css(rect):\\n  ...  \n","4  [(_trim_css_to_bounds, 1, def _trim_css_to_bou...  "],"text/html":["\n","  <div id=\"df-a901c4b8-3510-4738-a4da-591f89d06ab5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nwo</th>\n","      <th>path</th>\n","      <th>function_name</th>\n","      <th>content</th>\n","      <th>docstring_tokens</th>\n","      <th>url</th>\n","      <th>pairs</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>train</td>\n","      <td>def train(train_dir, model_save_path=None, n_n...</td>\n","      <td>Trains a k - nearest neighbors classifier for ...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>[(train, 1, def train(train_dir, model_save_pa...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>predict</td>\n","      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n","      <td>Recognizes faces in given image using a traine...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>[(predict, 1, def predict(X_img_path, knn_clf=...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>show_prediction_labels_on_image</td>\n","      <td>def show_prediction_labels_on_image(img_path, ...</td>\n","      <td>Shows the face recognition results visually .</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>[(show_prediction_labels_on_image, 1, def show...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_rect_to_css</td>\n","      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n","      <td>Convert a dlib rect object to a plain tuple in...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>[(_rect_to_css, 1, def _rect_to_css(rect):\\n  ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_trim_css_to_bounds</td>\n","      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n","      <td>Make sure a tuple in ( top right bottom left )...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>[(_trim_css_to_bounds, 1, def _trim_css_to_bou...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a901c4b8-3510-4738-a4da-591f89d06ab5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a901c4b8-3510-4738-a4da-591f89d06ab5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a901c4b8-3510-4738-a4da-591f89d06ab5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":73}],"source":["# The dataset containing a the name of the directory, its path, source code, and all the functions in a list extracted from the source code\n","df['pairs'] = func_doc\n","df.head()"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33t9Yzu0deoD","executionInfo":{"status":"ok","timestamp":1650977053922,"user_tz":-330,"elapsed":61177,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"f09afd6c-a6c1-4d67-9e13-cd4009cc9695"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 1min 1s, sys: 2.76 s, total: 1min 4s\n","Wall time: 1min 1s\n"]}],"source":["%%time\n","# flatten pairs\n","df = df.set_index(['nwo', 'path','function_name','content', 'docstring_tokens', 'url'])['pairs'].apply(pd.Series).stack()\n","df"]},{"cell_type":"code","source":["df = df.reset_index()\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":834},"id":"Hqfajfpdj8Rq","executionInfo":{"status":"ok","timestamp":1650977053923,"user_tz":-330,"elapsed":17,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"0d9cad7e-a160-4e6e-e864-77ad601d7b55"},"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                            nwo                              path  \\\n","0       face_recognition_knn.py  examples/face_recognition_knn.py   \n","1       face_recognition_knn.py  examples/face_recognition_knn.py   \n","2       face_recognition_knn.py  examples/face_recognition_knn.py   \n","3                        api.py           face_recognition/api.py   \n","4                        api.py           face_recognition/api.py   \n","...                         ...                               ...   \n","206174                 folia.py           pynlpl/formats/folia.py   \n","206175                 folia.py           pynlpl/formats/folia.py   \n","206176                 folia.py           pynlpl/formats/folia.py   \n","206177                 folia.py           pynlpl/formats/folia.py   \n","206178                 folia.py           pynlpl/formats/folia.py   \n","\n","                          function_name  \\\n","0                                 train   \n","1                               predict   \n","2       show_prediction_labels_on_image   \n","3                          _rect_to_css   \n","4                   _trim_css_to_bounds   \n","...                                 ...   \n","206174   AbstractElement.speech_speaker   \n","206175             AbstractElement.phon   \n","206176             AbstractElement.feat   \n","206177             AbstractElement.copy   \n","206178     AbstractElement.copychildren   \n","\n","                                                  content  \\\n","0       def train(train_dir, model_save_path=None, n_n...   \n","1       def predict(X_img_path, knn_clf=None, model_pa...   \n","2       def show_prediction_labels_on_image(img_path, ...   \n","3       def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n","4       def _trim_css_to_bounds(css, image_shape):\\n  ...   \n","...                                                   ...   \n","206174  def speech_speaker(self):\\n        \"\"\"Retrieve...   \n","206175  def phon(self, cls='current', previousdelimite...   \n","206176  def feat(self,subset):\\n        \"\"\"Obtain the ...   \n","206177  def copy(self, newdoc=None, idsuffix=\"\"):\\n   ...   \n","206178  def copychildren(self, newdoc=None, idsuffix=\"...   \n","\n","                                         docstring_tokens  \\\n","0       Trains a k - nearest neighbors classifier for ...   \n","1       Recognizes faces in given image using a traine...   \n","2           Shows the face recognition results visually .   \n","3       Convert a dlib rect object to a plain tuple in...   \n","4       Make sure a tuple in ( top right bottom left )...   \n","...                                                   ...   \n","206174  Retrieves the speaker of the audio or video fi...   \n","206175  Get the phonetic representation associated wit...   \n","206176  Obtain the feature class value of the specific...   \n","206177  Make a deep copy of this element and all its c...   \n","206178  Generator creating a deep copy of the children...   \n","\n","                                                      url  level_6  \\\n","0       https://github.com/ageitgey/face_recognition/b...        0   \n","1       https://github.com/ageitgey/face_recognition/b...        0   \n","2       https://github.com/ageitgey/face_recognition/b...        0   \n","3       https://github.com/ageitgey/face_recognition/b...        0   \n","4       https://github.com/ageitgey/face_recognition/b...        0   \n","...                                                   ...      ...   \n","206174  https://github.com/proycon/pynlpl/blob/7707f69...        0   \n","206175  https://github.com/proycon/pynlpl/blob/7707f69...        0   \n","206176  https://github.com/proycon/pynlpl/blob/7707f69...        0   \n","206177  https://github.com/proycon/pynlpl/blob/7707f69...        0   \n","206178  https://github.com/proycon/pynlpl/blob/7707f69...        0   \n","\n","                                                        0  \n","0       (train, 1, def train(train_dir, model_save_pat...  \n","1       (predict, 1, def predict(X_img_path, knn_clf=N...  \n","2       (show_prediction_labels_on_image, 1, def show_...  \n","3       (_rect_to_css, 1, def _rect_to_css(rect):\\n   ...  \n","4       (_trim_css_to_bounds, 1, def _trim_css_to_boun...  \n","...                                                   ...  \n","206174  (speech_speaker, 1, def speech_speaker(self):\\...  \n","206175  (phon, 1, def phon(self, cls='current', previo...  \n","206176  (feat, 1, def feat(self, subset):\\n    \"\"\"Obta...  \n","206177  (copy, 1, def copy(self, newdoc=None, idsuffix...  \n","206178  (copychildren, 1, def copychildren(self, newdo...  \n","\n","[206179 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-c042a4c9-7f0e-447a-816b-495ef7fe3743\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nwo</th>\n","      <th>path</th>\n","      <th>function_name</th>\n","      <th>content</th>\n","      <th>docstring_tokens</th>\n","      <th>url</th>\n","      <th>level_6</th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>train</td>\n","      <td>def train(train_dir, model_save_path=None, n_n...</td>\n","      <td>Trains a k - nearest neighbors classifier for ...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>0</td>\n","      <td>(train, 1, def train(train_dir, model_save_pat...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>predict</td>\n","      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n","      <td>Recognizes faces in given image using a traine...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>0</td>\n","      <td>(predict, 1, def predict(X_img_path, knn_clf=N...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>show_prediction_labels_on_image</td>\n","      <td>def show_prediction_labels_on_image(img_path, ...</td>\n","      <td>Shows the face recognition results visually .</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>0</td>\n","      <td>(show_prediction_labels_on_image, 1, def show_...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_rect_to_css</td>\n","      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n","      <td>Convert a dlib rect object to a plain tuple in...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>0</td>\n","      <td>(_rect_to_css, 1, def _rect_to_css(rect):\\n   ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_trim_css_to_bounds</td>\n","      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n","      <td>Make sure a tuple in ( top right bottom left )...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>0</td>\n","      <td>(_trim_css_to_bounds, 1, def _trim_css_to_boun...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>206174</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.speech_speaker</td>\n","      <td>def speech_speaker(self):\\n        \"\"\"Retrieve...</td>\n","      <td>Retrieves the speaker of the audio or video fi...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","      <td>0</td>\n","      <td>(speech_speaker, 1, def speech_speaker(self):\\...</td>\n","    </tr>\n","    <tr>\n","      <th>206175</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.phon</td>\n","      <td>def phon(self, cls='current', previousdelimite...</td>\n","      <td>Get the phonetic representation associated wit...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","      <td>0</td>\n","      <td>(phon, 1, def phon(self, cls='current', previo...</td>\n","    </tr>\n","    <tr>\n","      <th>206176</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.feat</td>\n","      <td>def feat(self,subset):\\n        \"\"\"Obtain the ...</td>\n","      <td>Obtain the feature class value of the specific...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","      <td>0</td>\n","      <td>(feat, 1, def feat(self, subset):\\n    \"\"\"Obta...</td>\n","    </tr>\n","    <tr>\n","      <th>206177</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.copy</td>\n","      <td>def copy(self, newdoc=None, idsuffix=\"\"):\\n   ...</td>\n","      <td>Make a deep copy of this element and all its c...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","      <td>0</td>\n","      <td>(copy, 1, def copy(self, newdoc=None, idsuffix...</td>\n","    </tr>\n","    <tr>\n","      <th>206178</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.copychildren</td>\n","      <td>def copychildren(self, newdoc=None, idsuffix=\"...</td>\n","      <td>Generator creating a deep copy of the children...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","      <td>0</td>\n","      <td>(copychildren, 1, def copychildren(self, newdo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>206179 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c042a4c9-7f0e-447a-816b-495ef7fe3743')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c042a4c9-7f0e-447a-816b-495ef7fe3743 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c042a4c9-7f0e-447a-816b-495ef7fe3743');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["df.columns = ['nwo', 'path','function_name','content', 'docstring_tokens', 'url', '_', 'pair']"],"metadata":{"id":"LqQW-xvkj_9l","executionInfo":{"status":"ok","timestamp":1650977053923,"user_tz":-330,"elapsed":15,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"7PxAtkhhdeoE","executionInfo":{"status":"ok","timestamp":1650977053923,"user_tz":-330,"elapsed":15,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"c0b3e744-6073-4d7f-be7c-560c692ab1eb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                       nwo                              path  \\\n","0  face_recognition_knn.py  examples/face_recognition_knn.py   \n","1  face_recognition_knn.py  examples/face_recognition_knn.py   \n","2  face_recognition_knn.py  examples/face_recognition_knn.py   \n","3                   api.py           face_recognition/api.py   \n","4                   api.py           face_recognition/api.py   \n","\n","                     function_name  \\\n","0                            train   \n","1                          predict   \n","2  show_prediction_labels_on_image   \n","3                     _rect_to_css   \n","4              _trim_css_to_bounds   \n","\n","                                             content  \\\n","0  def train(train_dir, model_save_path=None, n_n...   \n","1  def predict(X_img_path, knn_clf=None, model_pa...   \n","2  def show_prediction_labels_on_image(img_path, ...   \n","3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n","4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n","\n","                                    docstring_tokens  \\\n","0  Trains a k - nearest neighbors classifier for ...   \n","1  Recognizes faces in given image using a traine...   \n","2      Shows the face recognition results visually .   \n","3  Convert a dlib rect object to a plain tuple in...   \n","4  Make sure a tuple in ( top right bottom left )...   \n","\n","                                                 url  _  \\\n","0  https://github.com/ageitgey/face_recognition/b...  0   \n","1  https://github.com/ageitgey/face_recognition/b...  0   \n","2  https://github.com/ageitgey/face_recognition/b...  0   \n","3  https://github.com/ageitgey/face_recognition/b...  0   \n","4  https://github.com/ageitgey/face_recognition/b...  0   \n","\n","                                                pair  \n","0  (train, 1, def train(train_dir, model_save_pat...  \n","1  (predict, 1, def predict(X_img_path, knn_clf=N...  \n","2  (show_prediction_labels_on_image, 1, def show_...  \n","3  (_rect_to_css, 1, def _rect_to_css(rect):\\n   ...  \n","4  (_trim_css_to_bounds, 1, def _trim_css_to_boun...  "],"text/html":["\n","  <div id=\"df-34687960-059f-4528-9577-39d3d59369c0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nwo</th>\n","      <th>path</th>\n","      <th>function_name</th>\n","      <th>content</th>\n","      <th>docstring_tokens</th>\n","      <th>url</th>\n","      <th>_</th>\n","      <th>pair</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>train</td>\n","      <td>def train(train_dir, model_save_path=None, n_n...</td>\n","      <td>Trains a k - nearest neighbors classifier for ...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>0</td>\n","      <td>(train, 1, def train(train_dir, model_save_pat...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>predict</td>\n","      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n","      <td>Recognizes faces in given image using a traine...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>0</td>\n","      <td>(predict, 1, def predict(X_img_path, knn_clf=N...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>show_prediction_labels_on_image</td>\n","      <td>def show_prediction_labels_on_image(img_path, ...</td>\n","      <td>Shows the face recognition results visually .</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>0</td>\n","      <td>(show_prediction_labels_on_image, 1, def show_...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_rect_to_css</td>\n","      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n","      <td>Convert a dlib rect object to a plain tuple in...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>0</td>\n","      <td>(_rect_to_css, 1, def _rect_to_css(rect):\\n   ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_trim_css_to_bounds</td>\n","      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n","      <td>Make sure a tuple in ( top right bottom left )...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>0</td>\n","      <td>(_trim_css_to_bounds, 1, def _trim_css_to_boun...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34687960-059f-4528-9577-39d3d59369c0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-34687960-059f-4528-9577-39d3d59369c0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-34687960-059f-4528-9577-39d3d59369c0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":77}],"source":["df.head()"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBfj9LVIdeoE","executionInfo":{"status":"ok","timestamp":1650977054765,"user_tz":-330,"elapsed":856,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"99e151b2-0e8f-40da-ce25-dfdab7431f7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 380 ms, sys: 6.55 ms, total: 387 ms\n","Wall time: 388 ms\n"]}],"source":["%%time\n","df['lineno'] = df['pair'].apply(lambda p: p[1])\n","df['original_function'] = df['content']\n","df['function_tokens'] = df['pair'].apply(lambda p: p[3])\n","df = df[['nwo', 'path', 'function_name', 'lineno', 'original_function', 'function_tokens', 'docstring_tokens', 'url']]"]},{"cell_type":"code","execution_count":79,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"DuC-F-z0deoE","executionInfo":{"status":"ok","timestamp":1650977054765,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"f176341f-e274-4387-eecd-2db8a163bc05"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                       nwo                              path  \\\n","0  face_recognition_knn.py  examples/face_recognition_knn.py   \n","1  face_recognition_knn.py  examples/face_recognition_knn.py   \n","2  face_recognition_knn.py  examples/face_recognition_knn.py   \n","3                   api.py           face_recognition/api.py   \n","4                   api.py           face_recognition/api.py   \n","\n","                     function_name  lineno  \\\n","0                            train       1   \n","1                          predict       1   \n","2  show_prediction_labels_on_image       1   \n","3                     _rect_to_css       1   \n","4              _trim_css_to_bounds       1   \n","\n","                                   original_function  \\\n","0  def train(train_dir, model_save_path=None, n_n...   \n","1  def predict(X_img_path, knn_clf=None, model_pa...   \n","2  def show_prediction_labels_on_image(img_path, ...   \n","3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n","4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n","\n","                                     function_tokens  \\\n","0  train train dir model save path none neighbors...   \n","1  predict img path knn clf none model path none ...   \n","2  show prediction labels on image img path predi...   \n","3  rect to css rect return rect top rect right re...   \n","4  trim css to bounds css image shape return max ...   \n","\n","                                    docstring_tokens  \\\n","0  Trains a k - nearest neighbors classifier for ...   \n","1  Recognizes faces in given image using a traine...   \n","2      Shows the face recognition results visually .   \n","3  Convert a dlib rect object to a plain tuple in...   \n","4  Make sure a tuple in ( top right bottom left )...   \n","\n","                                                 url  \n","0  https://github.com/ageitgey/face_recognition/b...  \n","1  https://github.com/ageitgey/face_recognition/b...  \n","2  https://github.com/ageitgey/face_recognition/b...  \n","3  https://github.com/ageitgey/face_recognition/b...  \n","4  https://github.com/ageitgey/face_recognition/b...  "],"text/html":["\n","  <div id=\"df-8a1a1fee-5098-482c-adf9-0021a4ad4721\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nwo</th>\n","      <th>path</th>\n","      <th>function_name</th>\n","      <th>lineno</th>\n","      <th>original_function</th>\n","      <th>function_tokens</th>\n","      <th>docstring_tokens</th>\n","      <th>url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>train</td>\n","      <td>1</td>\n","      <td>def train(train_dir, model_save_path=None, n_n...</td>\n","      <td>train train dir model save path none neighbors...</td>\n","      <td>Trains a k - nearest neighbors classifier for ...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>predict</td>\n","      <td>1</td>\n","      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n","      <td>predict img path knn clf none model path none ...</td>\n","      <td>Recognizes faces in given image using a traine...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>show_prediction_labels_on_image</td>\n","      <td>1</td>\n","      <td>def show_prediction_labels_on_image(img_path, ...</td>\n","      <td>show prediction labels on image img path predi...</td>\n","      <td>Shows the face recognition results visually .</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_rect_to_css</td>\n","      <td>1</td>\n","      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n","      <td>rect to css rect return rect top rect right re...</td>\n","      <td>Convert a dlib rect object to a plain tuple in...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_trim_css_to_bounds</td>\n","      <td>1</td>\n","      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n","      <td>trim css to bounds css image shape return max ...</td>\n","      <td>Make sure a tuple in ( top right bottom left )...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a1a1fee-5098-482c-adf9-0021a4ad4721')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8a1a1fee-5098-482c-adf9-0021a4ad4721 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8a1a1fee-5098-482c-adf9-0021a4ad4721');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":79}],"source":["df.head()"]},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fX-hRCebdeoF","executionInfo":{"status":"ok","timestamp":1650977055424,"user_tz":-330,"elapsed":663,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"b9b9b7e6-b3b9-433e-ac52-2963d09ac5f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Removed 0 duplicate rows\n","CPU times: user 775 ms, sys: 8.73 ms, total: 784 ms\n","Wall time: 790 ms\n"]}],"source":["%%time\n","# remove observations where the same function definition appears more than once\n","before_dedup = len(df)\n","df = df.drop_duplicates(['original_function'])\n","after_dedup = len(df)\n","\n","print(f'Removed {before_dedup - after_dedup:,} duplicate rows')"]},{"cell_type":"code","execution_count":84,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZvFX145deoF","executionInfo":{"status":"ok","timestamp":1650977055424,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"a44a8579-723b-4eae-ad0c-c571495b080f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Removed 221 duplicate rows\n","CPU times: user 376 ms, sys: 7.81 ms, total: 384 ms\n","Wall time: 382 ms\n"]}],"source":["%%time\n","# remove observations which have the same function tokens appears more than once\n","before_dedup = len(df)\n","df = df.drop_duplicates(['function_tokens'])\n","after_dedup = len(df)\n","\n","print(f'Removed {before_dedup - after_dedup:,} duplicate rows')"]},{"cell_type":"code","execution_count":85,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D5tu3OswdeoF","executionInfo":{"status":"ok","timestamp":1650977055795,"user_tz":-330,"elapsed":374,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"da8241db-761c-4b88-acec-ed1c6c55846d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(205958, 8)"]},"metadata":{},"execution_count":85}],"source":["df.shape"]},{"cell_type":"markdown","metadata":{"id":"TXrkm9fedeoF"},"source":["### Separate function without docstrings\n"]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JIFHL5dQdeoF","executionInfo":{"status":"ok","timestamp":1650977057284,"user_tz":-330,"elapsed":1491,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"d4d98cad-4851-488c-f1ae-0088c3358107"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Funtion Snippets with docstring 202906\n","Number of Funtion Snippets without docstring 3052\n"]}],"source":["def listlen(x):\n","    if not isinstance(x, list):\n","        return 0\n","    return len(x)\n","\n","# separate functions without docstrings\n","# docstrings should be at least 3 words in the docstring to be considered a valid docstring\n","\n","with_docstrings = df[df.docstring_tokens.str.split().apply(listlen) >= 3]\n","without_docstrings = df[df.docstring_tokens.str.split().apply(listlen) < 3]\n","print('Number of Funtion Snippets with docstring',len(with_docstrings))\n","print('Number of Funtion Snippets without docstring',len(without_docstrings))"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"U4JqsqwxdeoF","executionInfo":{"status":"ok","timestamp":1650977069026,"user_tz":-330,"elapsed":11743,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["# Save the dataset of functions with docstrings\n","with_docstrings.to_csv('drive/MyDrive/CS657 IR PROJECT/processed_full.csv')"]},{"cell_type":"code","source":["# Using SQLlite to analyse the dataset\n","conn = sqlite3.connect('drive/MyDrive/CS657 IR PROJECT/with_docstrings.sqlite')\n","c=conn.cursor()\n","conn.text_factory = str\n","with_docstrings.to_sql('Data', conn,  schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)"],"metadata":{"id":"IA7n4qpDCUK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"wvNrzddZdeoG","executionInfo":{"status":"ok","timestamp":1650977089417,"user_tz":-330,"elapsed":19,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"11d8719d-22a2-4e94-fd40-f78331e095fd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                       nwo                              path  \\\n","0  face_recognition_knn.py  examples/face_recognition_knn.py   \n","1  face_recognition_knn.py  examples/face_recognition_knn.py   \n","2  face_recognition_knn.py  examples/face_recognition_knn.py   \n","3                   api.py           face_recognition/api.py   \n","4                   api.py           face_recognition/api.py   \n","\n","                     function_name  lineno  \\\n","0                            train       1   \n","1                          predict       1   \n","2  show_prediction_labels_on_image       1   \n","3                     _rect_to_css       1   \n","4              _trim_css_to_bounds       1   \n","\n","                                   original_function  \\\n","0  def train(train_dir, model_save_path=None, n_n...   \n","1  def predict(X_img_path, knn_clf=None, model_pa...   \n","2  def show_prediction_labels_on_image(img_path, ...   \n","3  def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n","4  def _trim_css_to_bounds(css, image_shape):\\n  ...   \n","\n","                                     function_tokens  \\\n","0  train train dir model save path none neighbors...   \n","1  predict img path knn clf none model path none ...   \n","2  show prediction labels on image img path predi...   \n","3  rect to css rect return rect top rect right re...   \n","4  trim css to bounds css image shape return max ...   \n","\n","                                    docstring_tokens  \\\n","0  Trains a k - nearest neighbors classifier for ...   \n","1  Recognizes faces in given image using a traine...   \n","2      Shows the face recognition results visually .   \n","3  Convert a dlib rect object to a plain tuple in...   \n","4  Make sure a tuple in ( top right bottom left )...   \n","\n","                                                 url  \n","0  https://github.com/ageitgey/face_recognition/b...  \n","1  https://github.com/ageitgey/face_recognition/b...  \n","2  https://github.com/ageitgey/face_recognition/b...  \n","3  https://github.com/ageitgey/face_recognition/b...  \n","4  https://github.com/ageitgey/face_recognition/b...  "],"text/html":["\n","  <div id=\"df-406bab03-6a78-4c3c-a526-4d25099aee29\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nwo</th>\n","      <th>path</th>\n","      <th>function_name</th>\n","      <th>lineno</th>\n","      <th>original_function</th>\n","      <th>function_tokens</th>\n","      <th>docstring_tokens</th>\n","      <th>url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>train</td>\n","      <td>1</td>\n","      <td>def train(train_dir, model_save_path=None, n_n...</td>\n","      <td>train train dir model save path none neighbors...</td>\n","      <td>Trains a k - nearest neighbors classifier for ...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>predict</td>\n","      <td>1</td>\n","      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n","      <td>predict img path knn clf none model path none ...</td>\n","      <td>Recognizes faces in given image using a traine...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>show_prediction_labels_on_image</td>\n","      <td>1</td>\n","      <td>def show_prediction_labels_on_image(img_path, ...</td>\n","      <td>show prediction labels on image img path predi...</td>\n","      <td>Shows the face recognition results visually .</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_rect_to_css</td>\n","      <td>1</td>\n","      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n","      <td>rect to css rect return rect top rect right re...</td>\n","      <td>Convert a dlib rect object to a plain tuple in...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_trim_css_to_bounds</td>\n","      <td>1</td>\n","      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n","      <td>trim css to bounds css image shape return max ...</td>\n","      <td>Make sure a tuple in ( top right bottom left )...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-406bab03-6a78-4c3c-a526-4d25099aee29')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-406bab03-6a78-4c3c-a526-4d25099aee29 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-406bab03-6a78-4c3c-a526-4d25099aee29');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":89}],"source":["with_docstrings.head()"]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pdUo8GpmdeoG","executionInfo":{"status":"ok","timestamp":1650977089417,"user_tz":-330,"elapsed":17,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"33a7e62d-e550-4545-965f-012d28b8d6df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of repositories - 21420\n"]}],"source":["# Number of unique repositories\n","print(\"Number of repositories -\",len(list(set(with_docstrings['nwo']))))"]},{"cell_type":"code","source":["with_docstrings['function_tokens_count'] = [len(item.split()) for item in list(with_docstrings['function_tokens'].values)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1TuL94AvESi","executionInfo":{"status":"ok","timestamp":1650977090421,"user_tz":-330,"elapsed":1017,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"b905daa8-aec7-4e05-d8b4-307c70164d06"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}]},{"cell_type":"code","execution_count":93,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":870},"id":"vDyNH4SwdeoG","executionInfo":{"status":"ok","timestamp":1650977090422,"user_tz":-330,"elapsed":4,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"0810bae9-6a2c-44c3-a266-cba9b0c8a3c5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                            nwo                              path  \\\n","0       face_recognition_knn.py  examples/face_recognition_knn.py   \n","1       face_recognition_knn.py  examples/face_recognition_knn.py   \n","2       face_recognition_knn.py  examples/face_recognition_knn.py   \n","3                        api.py           face_recognition/api.py   \n","4                        api.py           face_recognition/api.py   \n","...                         ...                               ...   \n","206174                 folia.py           pynlpl/formats/folia.py   \n","206175                 folia.py           pynlpl/formats/folia.py   \n","206176                 folia.py           pynlpl/formats/folia.py   \n","206177                 folia.py           pynlpl/formats/folia.py   \n","206178                 folia.py           pynlpl/formats/folia.py   \n","\n","                          function_name  lineno  \\\n","0                                 train       1   \n","1                               predict       1   \n","2       show_prediction_labels_on_image       1   \n","3                          _rect_to_css       1   \n","4                   _trim_css_to_bounds       1   \n","...                                 ...     ...   \n","206174   AbstractElement.speech_speaker       1   \n","206175             AbstractElement.phon       1   \n","206176             AbstractElement.feat       1   \n","206177             AbstractElement.copy       1   \n","206178     AbstractElement.copychildren       1   \n","\n","                                        original_function  \\\n","0       def train(train_dir, model_save_path=None, n_n...   \n","1       def predict(X_img_path, knn_clf=None, model_pa...   \n","2       def show_prediction_labels_on_image(img_path, ...   \n","3       def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...   \n","4       def _trim_css_to_bounds(css, image_shape):\\n  ...   \n","...                                                   ...   \n","206174  def speech_speaker(self):\\n        \"\"\"Retrieve...   \n","206175  def phon(self, cls='current', previousdelimite...   \n","206176  def feat(self,subset):\\n        \"\"\"Obtain the ...   \n","206177  def copy(self, newdoc=None, idsuffix=\"\"):\\n   ...   \n","206178  def copychildren(self, newdoc=None, idsuffix=\"...   \n","\n","                                          function_tokens  \\\n","0       train train dir model save path none neighbors...   \n","1       predict img path knn clf none model path none ...   \n","2       show prediction labels on image img path predi...   \n","3       rect to css rect return rect top rect right re...   \n","4       trim css to bounds css image shape return max ...   \n","...                                                   ...   \n","206174  speech speaker self if self speaker return sel...   \n","206175  phon self cls current previousdelimiter strict...   \n","206176  feat self subset none for in self if isinstanc...   \n","206177  copy self newdoc none idsuffix if idsuffix is ...   \n","206178  copychildren self newdoc none idsuffix if idsu...   \n","\n","                                         docstring_tokens  \\\n","0       Trains a k - nearest neighbors classifier for ...   \n","1       Recognizes faces in given image using a traine...   \n","2           Shows the face recognition results visually .   \n","3       Convert a dlib rect object to a plain tuple in...   \n","4       Make sure a tuple in ( top right bottom left )...   \n","...                                                   ...   \n","206174  Retrieves the speaker of the audio or video fi...   \n","206175  Get the phonetic representation associated wit...   \n","206176  Obtain the feature class value of the specific...   \n","206177  Make a deep copy of this element and all its c...   \n","206178  Generator creating a deep copy of the children...   \n","\n","                                                      url  \\\n","0       https://github.com/ageitgey/face_recognition/b...   \n","1       https://github.com/ageitgey/face_recognition/b...   \n","2       https://github.com/ageitgey/face_recognition/b...   \n","3       https://github.com/ageitgey/face_recognition/b...   \n","4       https://github.com/ageitgey/face_recognition/b...   \n","...                                                   ...   \n","206174  https://github.com/proycon/pynlpl/blob/7707f69...   \n","206175  https://github.com/proycon/pynlpl/blob/7707f69...   \n","206176  https://github.com/proycon/pynlpl/blob/7707f69...   \n","206177  https://github.com/proycon/pynlpl/blob/7707f69...   \n","206178  https://github.com/proycon/pynlpl/blob/7707f69...   \n","\n","        function_tokens_count  \n","0                         168  \n","1                         157  \n","2                          87  \n","3                          13  \n","4                          28  \n","...                       ...  \n","206174                     20  \n","206175                     88  \n","206176                     30  \n","206177                     24  \n","206178                     24  \n","\n","[202906 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-1ed73bf8-f5ed-43ab-b652-8b843c0f97d9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nwo</th>\n","      <th>path</th>\n","      <th>function_name</th>\n","      <th>lineno</th>\n","      <th>original_function</th>\n","      <th>function_tokens</th>\n","      <th>docstring_tokens</th>\n","      <th>url</th>\n","      <th>function_tokens_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>train</td>\n","      <td>1</td>\n","      <td>def train(train_dir, model_save_path=None, n_n...</td>\n","      <td>train train dir model save path none neighbors...</td>\n","      <td>Trains a k - nearest neighbors classifier for ...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>168</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>predict</td>\n","      <td>1</td>\n","      <td>def predict(X_img_path, knn_clf=None, model_pa...</td>\n","      <td>predict img path knn clf none model path none ...</td>\n","      <td>Recognizes faces in given image using a traine...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>157</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>face_recognition_knn.py</td>\n","      <td>examples/face_recognition_knn.py</td>\n","      <td>show_prediction_labels_on_image</td>\n","      <td>1</td>\n","      <td>def show_prediction_labels_on_image(img_path, ...</td>\n","      <td>show prediction labels on image img path predi...</td>\n","      <td>Shows the face recognition results visually .</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_rect_to_css</td>\n","      <td>1</td>\n","      <td>def _rect_to_css(rect):\\n    \"\"\"\\n    Convert ...</td>\n","      <td>rect to css rect return rect top rect right re...</td>\n","      <td>Convert a dlib rect object to a plain tuple in...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>api.py</td>\n","      <td>face_recognition/api.py</td>\n","      <td>_trim_css_to_bounds</td>\n","      <td>1</td>\n","      <td>def _trim_css_to_bounds(css, image_shape):\\n  ...</td>\n","      <td>trim css to bounds css image shape return max ...</td>\n","      <td>Make sure a tuple in ( top right bottom left )...</td>\n","      <td>https://github.com/ageitgey/face_recognition/b...</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>206174</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.speech_speaker</td>\n","      <td>1</td>\n","      <td>def speech_speaker(self):\\n        \"\"\"Retrieve...</td>\n","      <td>speech speaker self if self speaker return sel...</td>\n","      <td>Retrieves the speaker of the audio or video fi...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>206175</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.phon</td>\n","      <td>1</td>\n","      <td>def phon(self, cls='current', previousdelimite...</td>\n","      <td>phon self cls current previousdelimiter strict...</td>\n","      <td>Get the phonetic representation associated wit...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","      <td>88</td>\n","    </tr>\n","    <tr>\n","      <th>206176</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.feat</td>\n","      <td>1</td>\n","      <td>def feat(self,subset):\\n        \"\"\"Obtain the ...</td>\n","      <td>feat self subset none for in self if isinstanc...</td>\n","      <td>Obtain the feature class value of the specific...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>206177</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.copy</td>\n","      <td>1</td>\n","      <td>def copy(self, newdoc=None, idsuffix=\"\"):\\n   ...</td>\n","      <td>copy self newdoc none idsuffix if idsuffix is ...</td>\n","      <td>Make a deep copy of this element and all its c...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>206178</th>\n","      <td>folia.py</td>\n","      <td>pynlpl/formats/folia.py</td>\n","      <td>AbstractElement.copychildren</td>\n","      <td>1</td>\n","      <td>def copychildren(self, newdoc=None, idsuffix=\"...</td>\n","      <td>copychildren self newdoc none idsuffix if idsu...</td>\n","      <td>Generator creating a deep copy of the children...</td>\n","      <td>https://github.com/proycon/pynlpl/blob/7707f69...</td>\n","      <td>24</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>202906 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ed73bf8-f5ed-43ab-b652-8b843c0f97d9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1ed73bf8-f5ed-43ab-b652-8b843c0f97d9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1ed73bf8-f5ed-43ab-b652-8b843c0f97d9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":93}],"source":["with_docstrings"]},{"cell_type":"code","source":["# Using SQLlite to analyse the dataset\n","conn = sqlite3.connect('drive/MyDrive/CS657 IR PROJECT/with_docstrings.sqlite')\n","c=conn.cursor()\n","conn.text_factory = str\n","with_docstrings.to_sql('Data', conn,  schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)"],"metadata":{"id":"DNIbUughCaIR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":97,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"id":"GfjXyOCwdeoG","executionInfo":{"status":"ok","timestamp":1650977165192,"user_tz":-330,"elapsed":687,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"35945650-d06b-4fa7-f241-ebb906b0164a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 684x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","# Plotting the graph of sorted list of function tokens\n","plt.plot(sorted(list(with_docstrings['function_tokens_count'] .values)))\n","plt.ylabel('function_tokens_count')\n","plt.rcParams['figure.figsize'] = [9.5, 6]\n","plt.show()"]},{"cell_type":"code","source":["# Analysing what must be the minimum count of function tokens by seeing the values returned in sql queries\n","final = pd.read_sql_query(\"\"\"\n","SELECT *\n","FROM Data\n","WHERE function_tokens_count>4\n","ORDER BY function_tokens_count\n","\"\"\", conn)\n","final[:20]"],"metadata":{"id":"thfovA7xChyN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["final.shape"],"metadata":{"id":"ND2sn-TcCkL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":100,"metadata":{"scrolled":true,"id":"f8W7iW-4deoH","executionInfo":{"status":"ok","timestamp":1650977195717,"user_tz":-330,"elapsed":16615,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["conn = sqlite3.connect('drive/MyDrive/CS657 IR PROJECT/with_docstrings.sqlite')\n","c=conn.cursor()\n","conn.text_factory = str\n","final.to_sql('Modified', conn, schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":444},"id":"PQbJNUyjdeoH","executionInfo":{"status":"ok","timestamp":1650977196815,"user_tz":-330,"elapsed":1103,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"f99fe5f0-7a5a-4d61-ac6f-a42da76b3fe2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   level_0   index                nwo  \\\n","0     1628  143433        unpy2exe.py   \n","1     2471   92147  pytango_pprint.py   \n","2     2832  137370         easygui.py   \n","3     7457  185484        __init__.py   \n","4     8942   95349         connect.py   \n","\n","                                                path        function_name  \\\n","0                                        unpy2exe.py          __timestamp   \n","1                            tango/pytango_pprint.py  __struct_params_str   \n","2                              src/canari/easygui.py        __buttonEvent   \n","3  iotilebuild/iotile/build/config/scons-local-3....      __ensure_suffix   \n","4                                   pyVim/connect.py             __Logout   \n","\n","   lineno                                  original_function  \\\n","0       1  def __timestamp():\\n    \"\"\"Generate timestamp ...   \n","1       1  def __struct_params_str(obj, fmt, f=repr):\\n  ...   \n","2       1  def __buttonEvent(event):\\n    \"\"\"\\n    Handle...   \n","3       1  def __ensure_suffix(t, suffix):\\n    \"\"\" Ensur...   \n","4       1  def __Logout(si):\\n   \"\"\"\\n   Disconnect (logo...   \n","\n","                                     function_tokens  \\\n","0  timestamp today time time ret struct pack int ...   \n","1  struct params str obj fmt repr return struct p...   \n","2  buttonevent event global boxroot widgettexts r...   \n","3  ensure suffix suffix tpath str if not tpath en...   \n","4  logout si try if si content si retrievecontent...   \n","\n","                                    docstring_tokens  \\\n","0           Generate timestamp data for pyc header .   \n","1  method wrapper for printing all elements of a ...   \n","2  Handle an event that is generated by a person ...   \n","3    Ensure that the target t has the given suffix .   \n","4             Disconnect ( logout ) service instance   \n","\n","                                                 url  function_tokens_count  \n","0  https://github.com/matiasb/unpy2exe/blob/7a579...                     11  \n","1  https://github.com/tango-controls/pytango/blob...                     12  \n","2  https://github.com/redcanari/canari3/blob/322d...                     12  \n","3  https://github.com/iotile/coretools/blob/2d794...                     14  \n","4  https://github.com/vmware/pyvmomi/blob/3ffcb23...                     15  "],"text/html":["\n","  <div id=\"df-994e9dfa-13b3-4c32-9ff6-4fce5368b992\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>level_0</th>\n","      <th>index</th>\n","      <th>nwo</th>\n","      <th>path</th>\n","      <th>function_name</th>\n","      <th>lineno</th>\n","      <th>original_function</th>\n","      <th>function_tokens</th>\n","      <th>docstring_tokens</th>\n","      <th>url</th>\n","      <th>function_tokens_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1628</td>\n","      <td>143433</td>\n","      <td>unpy2exe.py</td>\n","      <td>unpy2exe.py</td>\n","      <td>__timestamp</td>\n","      <td>1</td>\n","      <td>def __timestamp():\\n    \"\"\"Generate timestamp ...</td>\n","      <td>timestamp today time time ret struct pack int ...</td>\n","      <td>Generate timestamp data for pyc header .</td>\n","      <td>https://github.com/matiasb/unpy2exe/blob/7a579...</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2471</td>\n","      <td>92147</td>\n","      <td>pytango_pprint.py</td>\n","      <td>tango/pytango_pprint.py</td>\n","      <td>__struct_params_str</td>\n","      <td>1</td>\n","      <td>def __struct_params_str(obj, fmt, f=repr):\\n  ...</td>\n","      <td>struct params str obj fmt repr return struct p...</td>\n","      <td>method wrapper for printing all elements of a ...</td>\n","      <td>https://github.com/tango-controls/pytango/blob...</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2832</td>\n","      <td>137370</td>\n","      <td>easygui.py</td>\n","      <td>src/canari/easygui.py</td>\n","      <td>__buttonEvent</td>\n","      <td>1</td>\n","      <td>def __buttonEvent(event):\\n    \"\"\"\\n    Handle...</td>\n","      <td>buttonevent event global boxroot widgettexts r...</td>\n","      <td>Handle an event that is generated by a person ...</td>\n","      <td>https://github.com/redcanari/canari3/blob/322d...</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7457</td>\n","      <td>185484</td>\n","      <td>__init__.py</td>\n","      <td>iotilebuild/iotile/build/config/scons-local-3....</td>\n","      <td>__ensure_suffix</td>\n","      <td>1</td>\n","      <td>def __ensure_suffix(t, suffix):\\n    \"\"\" Ensur...</td>\n","      <td>ensure suffix suffix tpath str if not tpath en...</td>\n","      <td>Ensure that the target t has the given suffix .</td>\n","      <td>https://github.com/iotile/coretools/blob/2d794...</td>\n","      <td>14</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8942</td>\n","      <td>95349</td>\n","      <td>connect.py</td>\n","      <td>pyVim/connect.py</td>\n","      <td>__Logout</td>\n","      <td>1</td>\n","      <td>def __Logout(si):\\n   \"\"\"\\n   Disconnect (logo...</td>\n","      <td>logout si try if si content si retrievecontent...</td>\n","      <td>Disconnect ( logout ) service instance</td>\n","      <td>https://github.com/vmware/pyvmomi/blob/3ffcb23...</td>\n","      <td>15</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-994e9dfa-13b3-4c32-9ff6-4fce5368b992')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-994e9dfa-13b3-4c32-9ff6-4fce5368b992 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-994e9dfa-13b3-4c32-9ff6-4fce5368b992');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":101}],"source":["# checking if functions which are overridden are of importance to us\n","check = pd.read_sql_query(\"\"\"\n","SELECT *\n","FROM Modified\n","WHERE function_name LIKE '!_!_%' ESCAPE'!'\n","ORDER BY function_tokens_count\n","\"\"\", conn)\n","check.head()"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"oQiLw8FwdeoH","executionInfo":{"status":"ok","timestamp":1650977212942,"user_tz":-330,"elapsed":16132,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["final.to_csv('drive/MyDrive/CS657 IR PROJECT/processed_full2.csv')"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"0xp1O_s6deoH","executionInfo":{"status":"ok","timestamp":1650977212943,"user_tz":-330,"elapsed":11,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["#Grouping entries by thie repository name\n","grouped = final.groupby('nwo')"]},{"cell_type":"code","execution_count":104,"metadata":{"id":"KF1eamzfdeoH","executionInfo":{"status":"ok","timestamp":1650977214269,"user_tz":-330,"elapsed":1336,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["# train, valid, test splits\n","train, valid = train_test_split(list(grouped), train_size=0.9, random_state=8081)\n","train, test = train_test_split(train, train_size=0.9, random_state=8081)"]},{"cell_type":"code","execution_count":105,"metadata":{"id":"xEUBBtdldeoH","executionInfo":{"status":"ok","timestamp":1650977228161,"user_tz":-330,"elapsed":13896,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["train = pd.concat([d for _, d in train]).reset_index(drop=True)\n","valid = pd.concat([d for _, d in valid]).reset_index(drop=True)\n","test = pd.concat([d for _, d in test]).reset_index(drop=True)"]},{"cell_type":"code","execution_count":108,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMkZfOSYdeoH","executionInfo":{"status":"ok","timestamp":1650977228167,"user_tz":-330,"elapsed":46,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"6567007b-3db4-473f-9c7a-99b32cf7ed6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["train set num rows 161,098\n","valid set num rows 24,469\n","test set num rows 17,313\n","without docstring rows 3,052\n"]}],"source":["print(f'train set num rows {train.shape[0]:,}')\n","print(f'valid set num rows {valid.shape[0]:,}')\n","print(f'test set num rows {test.shape[0]:,}')\n","print(f'without docstring rows {without_docstrings.shape[0]:,}')"]},{"cell_type":"code","execution_count":109,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"id":"gr7AgrqCdeoH","executionInfo":{"status":"ok","timestamp":1650977228168,"user_tz":-330,"elapsed":38,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}},"outputId":"79a199cd-d24d-4f97-9ad1-0c909aa41dfb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   index       nwo                        path  \\\n","0  97295  gandi.py  lexicon/providers/gandi.py   \n","1  97296  gandi.py  lexicon/providers/gandi.py   \n","2  97294  gandi.py  lexicon/providers/gandi.py   \n","3  97297  gandi.py  lexicon/providers/gandi.py   \n","4  97299  gandi.py  lexicon/providers/gandi.py   \n","\n","                       function_name  lineno  \\\n","0   GandiRPCSubProvider.authenticate       1   \n","1  GandiRPCSubProvider.create_record       1   \n","2            Provider._update_record       1   \n","3   GandiRPCSubProvider.list_records       1   \n","4  GandiRPCSubProvider.delete_record       1   \n","\n","                                   original_function  \\\n","0  def authenticate(self):\\n        \"\"\"Determine ...   \n","1  def create_record(self, rtype, name, content, ...   \n","2  def _update_record(self, identifier, rtype=Non...   \n","3  def list_records(self, rtype=None, name=None, ...   \n","4  def delete_record(self, identifier=None, rtype...   \n","\n","                                     function_tokens  \\\n","0  authenticate self try payload self api domain ...   \n","1  create record self rtype name content ttl vers...   \n","2  update record self identifier rtype none name ...   \n","3  list records self rtype none name none content...   \n","4  delete record self identifier none rtype none ...   \n","\n","                                    docstring_tokens  \\\n","0  Determine the current domain and zone IDs for ...   \n","1  Creates a record for the domain in a new Gandi...   \n","2   Updates the specified record in a new Gandi zone   \n","3  List all record for the domain in the active G...   \n","4  Removes the specified records in a new Gandi z...   \n","\n","                                                 url  function_tokens_count  \n","0  https://github.com/AnalogJ/lexicon/blob/9330b8...                     35  \n","1  https://github.com/AnalogJ/lexicon/blob/9330b8...                     91  \n","2  https://github.com/AnalogJ/lexicon/blob/9330b8...                    112  \n","3  https://github.com/AnalogJ/lexicon/blob/9330b8...                    113  \n","4  https://github.com/AnalogJ/lexicon/blob/9330b8...                    173  "],"text/html":["\n","  <div id=\"df-d4375eb0-a065-48e6-adb3-286c077e4eeb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>nwo</th>\n","      <th>path</th>\n","      <th>function_name</th>\n","      <th>lineno</th>\n","      <th>original_function</th>\n","      <th>function_tokens</th>\n","      <th>docstring_tokens</th>\n","      <th>url</th>\n","      <th>function_tokens_count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>97295</td>\n","      <td>gandi.py</td>\n","      <td>lexicon/providers/gandi.py</td>\n","      <td>GandiRPCSubProvider.authenticate</td>\n","      <td>1</td>\n","      <td>def authenticate(self):\\n        \"\"\"Determine ...</td>\n","      <td>authenticate self try payload self api domain ...</td>\n","      <td>Determine the current domain and zone IDs for ...</td>\n","      <td>https://github.com/AnalogJ/lexicon/blob/9330b8...</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>97296</td>\n","      <td>gandi.py</td>\n","      <td>lexicon/providers/gandi.py</td>\n","      <td>GandiRPCSubProvider.create_record</td>\n","      <td>1</td>\n","      <td>def create_record(self, rtype, name, content, ...</td>\n","      <td>create record self rtype name content ttl vers...</td>\n","      <td>Creates a record for the domain in a new Gandi...</td>\n","      <td>https://github.com/AnalogJ/lexicon/blob/9330b8...</td>\n","      <td>91</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>97294</td>\n","      <td>gandi.py</td>\n","      <td>lexicon/providers/gandi.py</td>\n","      <td>Provider._update_record</td>\n","      <td>1</td>\n","      <td>def _update_record(self, identifier, rtype=Non...</td>\n","      <td>update record self identifier rtype none name ...</td>\n","      <td>Updates the specified record in a new Gandi zone</td>\n","      <td>https://github.com/AnalogJ/lexicon/blob/9330b8...</td>\n","      <td>112</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>97297</td>\n","      <td>gandi.py</td>\n","      <td>lexicon/providers/gandi.py</td>\n","      <td>GandiRPCSubProvider.list_records</td>\n","      <td>1</td>\n","      <td>def list_records(self, rtype=None, name=None, ...</td>\n","      <td>list records self rtype none name none content...</td>\n","      <td>List all record for the domain in the active G...</td>\n","      <td>https://github.com/AnalogJ/lexicon/blob/9330b8...</td>\n","      <td>113</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>97299</td>\n","      <td>gandi.py</td>\n","      <td>lexicon/providers/gandi.py</td>\n","      <td>GandiRPCSubProvider.delete_record</td>\n","      <td>1</td>\n","      <td>def delete_record(self, identifier=None, rtype...</td>\n","      <td>delete record self identifier none rtype none ...</td>\n","      <td>Removes the specified records in a new Gandi z...</td>\n","      <td>https://github.com/AnalogJ/lexicon/blob/9330b8...</td>\n","      <td>173</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4375eb0-a065-48e6-adb3-286c077e4eeb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d4375eb0-a065-48e6-adb3-286c077e4eeb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d4375eb0-a065-48e6-adb3-286c077e4eeb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":109}],"source":["train.head()"]},{"cell_type":"code","execution_count":110,"metadata":{"id":"dzeIxhwJdeoI","executionInfo":{"status":"ok","timestamp":1650977228746,"user_tz":-330,"elapsed":607,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["train.sort_values(by=['function_tokens_count'], inplace=True)\n","valid.sort_values(by=['function_tokens_count'], inplace=True)\n","test.sort_values(by=['function_tokens_count'], inplace=True)"]},{"cell_type":"code","execution_count":111,"metadata":{"id":"ASzbZQmjdeoI","executionInfo":{"status":"ok","timestamp":1650977240738,"user_tz":-330,"elapsed":11996,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["train.to_csv('drive/MyDrive/CS657 IR PROJECT/train_sorted.csv')\n","valid.to_csv('drive/MyDrive/CS657 IR PROJECT/valid_sorted.csv')\n","test.to_csv('drive/MyDrive/CS657 IR PROJECT/test_sorted.csv')"]},{"cell_type":"code","execution_count":112,"metadata":{"id":"Hg3TygEldeoI","executionInfo":{"status":"ok","timestamp":1650977240739,"user_tz":-330,"elapsed":13,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["with open('drive/MyDrive/CS657 IR PROJECT/docstrings.txt', 'w') as f:\n","    for item in train['docstring_tokens'].values:  # Write only the docstrings into a txt file\n","        f.write(\"%s\\n\" % item) # One docstring per line"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"j3IXunQedeoI","executionInfo":{"status":"ok","timestamp":1650977241714,"user_tz":-330,"elapsed":987,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"outputs":[],"source":["with open('drive/MyDrive/CS657 IR PROJECT/function_tokens.txt', 'w') as f:\n","    for item in train['function_tokens'].values:  # Write only the docstrings into a txt file\n","        f.write(\"%s\\n\" % item) # One docstring per line"]},{"cell_type":"code","source":["with open('drive/MyDrive/CS657 IR PROJECT/Original_function.txt', 'w') as f:\n","    for item in train['original_function'].values:  # Write only the docstrings into a txt file\n","        f.write(\"%s\\n\" % item) # One docstring per line"],"metadata":{"id":"oGmU2OdeiL4B","executionInfo":{"status":"ok","timestamp":1650977243395,"user_tz":-330,"elapsed":1685,"user":{"displayName":"Shubham Sinha","userId":"10541463333995057505"}}},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":["**Part 1 Completed**"],"metadata":{"id":"bLlXKVcnfOYO"}}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"colab":{"name":"Part 1 IR PROJECT.ipynb","provenance":[{"file_id":"1w-OntBMMozdUp-DUJF6Bi6cDD2jIJO5k","timestamp":1650971512682}],"collapsed_sections":[]},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}